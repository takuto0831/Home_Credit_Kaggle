{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Credit competition\n",
    "\n",
    "- 他のチームの結果を参考に, LightGBMの使い方, pythonコードの作成方法についてまとめる\n",
    "- コメント文など適宜追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Kaggle:How to LightGBM with lightgbm.cv](https://www.kaggle.com/shep312/lightgbm-harder-better-slower/code)\n",
    "- [Python API](https://lightgbm.readthedocs.io/en/latest/Python-API.html)\n",
    "- [roc auc score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html0)\n",
    "- [1st place solution](https://www.kaggle.com/c/home-credit-default-risk/discussion/64821)\n",
    "- [2nd place solution](https://www.kaggle.com/c/home-credit-default-risk/discussion/64722)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winner session summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important thing is\n",
    "\n",
    "- Good set of smart features\n",
    "- Diverse set of base algorithms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import gc, os, sys, warnings,time\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from contextlib import contextmanager\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "\n",
    "# set path\n",
    "sys.path.append(\"/Users/takuto/Desktop/Home_Credit_Kaggle/py/\") # for macbook\n",
    "sys.path.append(\"/Users/takutokotsubo/Desktop/Home_Credit_Kaggle/py/\") # for imac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function\n",
    "\n",
    "- @contextmanager: with文を用いて簡単に実行時間を計測できる関数を作成できる\n",
    "- one-hot: デジタル回路において, 1つだけ\"1\"の値をとり, 他の全ての値が\"0\"であるようなビット列, ダミー変数化では0,1の値を用いて区別するので少し意味合いが違うことに注意\n",
    "- gc.collect(): del -> gc.collect()でメモリを開放でできる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution time measuring\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "    \n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "# not using\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "    df = pd.get_dummies(df, columns = categorical_columns, dummy_na = nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df,new_columns\n",
    "\n",
    "# preprocess all data\n",
    "# not using\n",
    "def read_all_data(num_rows = None, nan_as_category = False):\n",
    "    df = pd.read_csv(\"../input/csv_imp1/all_data_train.csv\", nrows = num_rows)\n",
    "    test = pd.read_csv(\"../input/csv_imp1/all_data_test.csv\", nrows = num_rows)\n",
    "    df = df.append(test).reset_index()\n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    # for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "    #    df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    del test\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "# LightGBM with cv, not completed !!!!!!!!!!!\n",
    "def lightgbm_cv(df, num_folds, NFOLD, LOOP, debug = False):\n",
    "    # parameters\n",
    "    param = {\n",
    "         'objective': 'binary',\n",
    "         'metric': 'auc',\n",
    "         'learning_rate': 0.01,\n",
    "         'max_depth': 6,\n",
    "         'num_leaves': 63,\n",
    "         'max_bin': 255,\n",
    "         'min_child_weight': 10,\n",
    "         'min_data_in_leaf': 150,\n",
    "         'reg_lambda': 0.5,  # L2 regularization term on weights.\n",
    "         'reg_alpha': 0.5,  # L1 regularization term on weights.\n",
    "         'colsample_bytree': 0.9,\n",
    "         'subsample': 0.9,\n",
    "         'nthread': cpu_count(),\n",
    "         'bagging_freq': 1,\n",
    "         'verbose':-1,\n",
    "         }\n",
    "    train_df = pd.read_csv(\"../input/csv_imp1/all_data_train.csv\", nrows = num_rows)\n",
    "    test_df = pd.read_csv(\"../input/csv_imp1/all_data_test.csv\", nrows = num_rows)\n",
    "    print(\"Starting Light GBM. Train shape: {}, test shape: {}\".format(train_df.shape, test_df.shape))\n",
    "    del df; gc.collect()\n",
    "    # non list\n",
    "    feats = [f for f in train_df.columns if f not in [\"TARGET\",\"SK_ID_CURR\",\"SK_ID_BUREAU\",\"SK_ID_PREV\",\"index\"]]\n",
    "    train_x, train_y, test_X = train_df[feats], train_df[\"TARGET\"], test_df[feats]      \n",
    "    dtrain = lgb.Dataset(train_x,train_y)\n",
    "    gc.collect()\n",
    "    # result box\n",
    "    model_all = []\n",
    "    y_pred = pd.Series(0, index=train_y.index)\n",
    "    \n",
    "    # training with cv\n",
    "    for i in range(LOOP):\n",
    "        gc.collect()\n",
    "        ret, models = lgb.cv(param, dtrain, 9999, nfold=NFOLD,\n",
    "                             early_stopping_rounds=100, verbose_eval=50, seed=i)\n",
    "        model_all += models\n",
    "        \n",
    "# Display/plot feature importance\n",
    "# maybe not need \n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('lgbm_importances01.png')\n",
    "\n",
    "# send message to line\n",
    "def send_line(message):\n",
    "    line_notify_token = '5p5sPTY7PrQaB8Wnwp6aadfiqC8m2zh6Q8llrfNisGT'\n",
    "    line_notify_api = 'https://notify-api.line.me/api/notify'\n",
    "    payload = {'message': message}\n",
    "    headers = {'Authorization': 'Bearer ' + line_notify_token}\n",
    "    requests.post(line_notify_api, data=payload, headers=headers)\n",
    "\n",
    "# main, not completed !!!!!!!!!!\n",
    "def main(debug = False):\n",
    "    num_rows = 100000 if debug else None # for debug\n",
    "    df = read_all_data(num_rows)\n",
    "    with timer(\"Run LightGBM with kfold\"):\n",
    "        feat_importance = kfold_lightgbm(df, num_folds= 5, stratified= False, debug= debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- メモ形式\n",
    "- 完成したら関数化\n",
    "- 重要な特徴量の抽出も可能にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function para\n",
    "LOOP = 1\n",
    "NFOLD = 5 # good set: 7\n",
    "num_rows = None # good set: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "## imp_csv0\n",
    "train_df = pd.read_csv(\"../input/csv_imp0/all_data_train.csv\", nrows = num_rows)\n",
    "test_df = pd.read_csv(\"../input/csv_imp0/all_data_test.csv\", nrows = num_rows)\n",
    "## imp_csv1\n",
    "# train_df = pd.read_csv(\"../input/csv_imp1/all_data_train.csv\", nrows = num_rows)\n",
    "# test_df = pd.read_csv(\"../input/csv_imp1/all_data_test.csv\", nrows = num_rows)\n",
    "\n",
    "# select using columns\n",
    "## all colmuns\n",
    "feats = [f for f in train_df.columns if f not in [\"target_app\",\"sk_id_curr\",\"sk_id_bureau\",\"sk_id_prev\"]]\n",
    "## best columns\n",
    "# feats = pd.read_table(\"../data/best_para.tsv\")\n",
    "# feats = feats[\"Feature\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 6,\n",
    "    'num_leaves': 63,\n",
    "    'max_bin': 255,\n",
    "    \n",
    "    'min_child_weight': 10,\n",
    "    'min_data_in_leaf': 150,\n",
    "    'reg_lambda': 0.5,  # L2 regularization term on weights.\n",
    "    'reg_alpha': 0.5,  # L1 regularization term on weights.\n",
    "         \n",
    "    'colsample_bytree': 0.9,\n",
    "    'subsample': 0.9,\n",
    "    'nthread': cpu_count(),\n",
    "    'bagging_freq': 1,\n",
    "    'verbose':-1,\n",
    "}\n",
    "# make data set\n",
    "X_train, y_train, X_test = train_df[feats], train_df[\"target_app\"], test_df[feats]      \n",
    "dtrain = lgb.Dataset(X_train,y_train,free_raw_data=False)\n",
    "gc.collect()\n",
    "# result box\n",
    "model_all = []\n",
    "y_pred = pd.Series(0, index=y_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with cv\n",
    "for i in range(LOOP):\n",
    "    gc.collect()\n",
    "    # cross validation\n",
    "    print(\"Starting Light GBM {}-fold cross varidation. Train shape: {}, test shape: {}\"\n",
    "          .format(NFOLD, train_df.shape, test_df.shape))\n",
    "    models_cv = lgb.cv(param, dtrain, 9999, nfold=NFOLD,\n",
    "                       early_stopping_rounds=100, verbose_eval=50, seed=i)\n",
    "    print(\"best n_estimator\", len(models_cv[\"auc-mean\"])) # best iteration\n",
    "    print(\"best cv score\", models_cv[\"auc-mean\"][-1]) # best cv score\n",
    "    # execute model\n",
    "    print(\"Starting Light GBM Training. Train shape: {}, test shape: {}, best iter: {}\"\n",
    "          .format(train_df.shape, test_df.shape, len(models_cv[\"auc-mean\"])))\n",
    "    models_train = lgb.train(param,dtrain,num_boost_round=len(models_cv[\"auc-mean\"]))\n",
    "    # predict target (model.best_iteration??)\n",
    "    print(\"Starting Light GBM Predict. Train shape: {}, test shape: {}, num iter: {}\"\n",
    "          .format(train_df.shape, test_df.shape, model.best_iteration))\n",
    "    pred_train = models_train.predict(train_x)\n",
    "    \n",
    "    # roc_auc score\n",
    "    auc_mean = roc_auc_score(train_y,pred_train)\n",
    "    print(f\"CV auc-mean(loop {i}): {auc_mean} {models['auc-mean'][-1]}\")\n",
    "    \n",
    "    #model_all += models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- さらに細かいメモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Light GBM 5-fold cross varidation. Train shape: (307511, 1309), test shape: (48744, 1309)\n",
      "[50]\tcv_agg's auc: 0.743005 + 0.00141292\n",
      "[100]\tcv_agg's auc: 0.750913 + 0.00141804\n",
      "[150]\tcv_agg's auc: 0.757032 + 0.00116147\n",
      "[200]\tcv_agg's auc: 0.76238 + 0.00113755\n",
      "[250]\tcv_agg's auc: 0.767197 + 0.000981763\n",
      "[300]\tcv_agg's auc: 0.770956 + 0.000897454\n",
      "[350]\tcv_agg's auc: 0.773852 + 0.000912315\n",
      "[400]\tcv_agg's auc: 0.776179 + 0.000977148\n",
      "[450]\tcv_agg's auc: 0.778041 + 0.00109723\n",
      "[500]\tcv_agg's auc: 0.779664 + 0.00112941\n",
      "[550]\tcv_agg's auc: 0.78101 + 0.00124438\n",
      "[600]\tcv_agg's auc: 0.782161 + 0.00127704\n",
      "[650]\tcv_agg's auc: 0.783214 + 0.00134361\n",
      "[700]\tcv_agg's auc: 0.784082 + 0.00141449\n",
      "[750]\tcv_agg's auc: 0.784872 + 0.0014907\n",
      "[800]\tcv_agg's auc: 0.785539 + 0.00153992\n",
      "[850]\tcv_agg's auc: 0.78616 + 0.00161908\n",
      "[900]\tcv_agg's auc: 0.786697 + 0.00167577\n",
      "[950]\tcv_agg's auc: 0.787172 + 0.00168669\n",
      "[1000]\tcv_agg's auc: 0.78764 + 0.00172747\n",
      "[1050]\tcv_agg's auc: 0.787991 + 0.00176749\n",
      "[1100]\tcv_agg's auc: 0.788348 + 0.00180496\n",
      "[1150]\tcv_agg's auc: 0.788715 + 0.00184572\n",
      "[1200]\tcv_agg's auc: 0.789048 + 0.00187793\n",
      "[1250]\tcv_agg's auc: 0.789321 + 0.00191295\n",
      "[1300]\tcv_agg's auc: 0.789625 + 0.00194267\n",
      "[1350]\tcv_agg's auc: 0.789864 + 0.00199333\n",
      "[1400]\tcv_agg's auc: 0.790071 + 0.00200585\n",
      "[1450]\tcv_agg's auc: 0.790286 + 0.00204762\n",
      "[1500]\tcv_agg's auc: 0.790491 + 0.00204182\n",
      "[1550]\tcv_agg's auc: 0.790657 + 0.00205373\n",
      "[1600]\tcv_agg's auc: 0.790802 + 0.00206038\n",
      "[1650]\tcv_agg's auc: 0.790971 + 0.00207962\n",
      "[1700]\tcv_agg's auc: 0.791111 + 0.00207669\n",
      "[1750]\tcv_agg's auc: 0.791271 + 0.00212162\n",
      "[1800]\tcv_agg's auc: 0.791401 + 0.00214352\n",
      "[1850]\tcv_agg's auc: 0.791496 + 0.00216362\n",
      "[1900]\tcv_agg's auc: 0.791577 + 0.00214542\n",
      "[1950]\tcv_agg's auc: 0.7917 + 0.00216639\n",
      "[2000]\tcv_agg's auc: 0.791797 + 0.00216186\n",
      "[2050]\tcv_agg's auc: 0.791876 + 0.0022001\n",
      "[2100]\tcv_agg's auc: 0.791986 + 0.0022094\n",
      "[2150]\tcv_agg's auc: 0.792075 + 0.00223587\n",
      "[2200]\tcv_agg's auc: 0.792133 + 0.00225553\n",
      "[2250]\tcv_agg's auc: 0.792173 + 0.00226081\n",
      "[2300]\tcv_agg's auc: 0.792247 + 0.00227755\n",
      "[2350]\tcv_agg's auc: 0.792343 + 0.00229961\n",
      "[2400]\tcv_agg's auc: 0.792384 + 0.00231576\n",
      "[2450]\tcv_agg's auc: 0.792437 + 0.00234341\n",
      "[2500]\tcv_agg's auc: 0.792506 + 0.00233116\n",
      "[2550]\tcv_agg's auc: 0.792549 + 0.00231832\n",
      "[2600]\tcv_agg's auc: 0.792606 + 0.00234527\n",
      "[2650]\tcv_agg's auc: 0.792691 + 0.00235255\n",
      "[2700]\tcv_agg's auc: 0.792732 + 0.00236118\n",
      "[2750]\tcv_agg's auc: 0.792768 + 0.00237063\n",
      "[2800]\tcv_agg's auc: 0.792787 + 0.00239142\n",
      "[2850]\tcv_agg's auc: 0.792812 + 0.00236559\n",
      "[2900]\tcv_agg's auc: 0.792855 + 0.00238421\n",
      "[2950]\tcv_agg's auc: 0.792889 + 0.00238704\n",
      "[3000]\tcv_agg's auc: 0.792901 + 0.00239103\n",
      "[3050]\tcv_agg's auc: 0.792915 + 0.00241508\n",
      "[3100]\tcv_agg's auc: 0.792921 + 0.00243716\n",
      "[3150]\tcv_agg's auc: 0.792927 + 0.00243481\n",
      "[3200]\tcv_agg's auc: 0.792936 + 0.00242488\n",
      "[3250]\tcv_agg's auc: 0.792957 + 0.00242566\n",
      "[3300]\tcv_agg's auc: 0.792982 + 0.00244011\n",
      "[3350]\tcv_agg's auc: 0.792996 + 0.0024407\n",
      "[3400]\tcv_agg's auc: 0.793032 + 0.00242028\n",
      "[3450]\tcv_agg's auc: 0.793034 + 0.00239656\n",
      "[3500]\tcv_agg's auc: 0.793045 + 0.00237205\n",
      "[3550]\tcv_agg's auc: 0.793041 + 0.00237825\n",
      "best n_estimator 3486\n",
      "best cv score 0.7930558603571797\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "print(\"Starting Light GBM {}-fold cross varidation. Train shape: {}, test shape: {}\"\n",
    "      .format(NFOLD, train_df.shape, test_df.shape))\n",
    "models_cv = lgb.cv(param, dtrain, 9999, nfold=NFOLD,\n",
    "                   early_stopping_rounds=100, verbose_eval=50, seed=i)\n",
    "print(\"best n_estimator\", len(models_cv[\"auc-mean\"])) # best iteration\n",
    "print(\"best cv score\", models_cv[\"auc-mean\"][-1]) # best cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Light GBM Training. Train shape: (307511, 1309), test shape: (48744, 1309), best iter: 3486\n",
      "best model iteration: 0\n",
      "best model score: defaultdict(<class 'dict'>, {})\n"
     ]
    }
   ],
   "source": [
    "# execute model\n",
    "print(\"Starting Light GBM Training. Train shape: {}, test shape: {}, best iter: {}\"\n",
    "      .format(train_df.shape, test_df.shape, len(models_cv[\"auc-mean\"])))\n",
    "models_train = lgb.train(param,dtrain,num_boost_round=len(models_cv[\"auc-mean\"]))\n",
    "# print(\"best model iteration: {}\" .format(models_train.best_iteration)) # best iteration\n",
    "# print(\"best model score: {}\" .format(models_train.best_score)) # best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Light GBM Predict. Train shape: (307511, 1309), test shape: (48744, 1309), num iter: 0\n"
     ]
    }
   ],
   "source": [
    "# predict target (model.best_iteration??)\n",
    "print(\"Starting Light GBM Predict. Train shape: {}, test shape: {}, num iter: {}\"\n",
    "      .format(train_df.shape, test_df.shape, models_train.best_iteration))\n",
    "pred_train = models_train.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light GBM 5-fold cross models_cvcvtion. loop: 1, auc_score:0.9021944332186309, cv score: 0.7930558603571797\n"
     ]
    }
   ],
   "source": [
    "# roc_auc score ( 1に近いほどよい)\n",
    "auc_mean = roc_auc_score(np.array(y_train),pred_train)\n",
    "print(\"Light GBM {}-fold cross models_cvcvtion. loop: {}, auc_score:{}, cv score: {}\"\n",
    "      .format(NFOLD, i, auc_mean, models_cv[\"auc-mean\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test data\n",
    "pred_test = models_train.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307511</th>\n",
       "      <td>100001</td>\n",
       "      <td>0.027910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307512</th>\n",
       "      <td>100005</td>\n",
       "      <td>0.123406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307513</th>\n",
       "      <td>100013</td>\n",
       "      <td>0.034792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307514</th>\n",
       "      <td>100028</td>\n",
       "      <td>0.047855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307515</th>\n",
       "      <td>100038</td>\n",
       "      <td>0.136660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307516</th>\n",
       "      <td>100042</td>\n",
       "      <td>0.035730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307517</th>\n",
       "      <td>100057</td>\n",
       "      <td>0.006980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307518</th>\n",
       "      <td>100065</td>\n",
       "      <td>0.022482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307519</th>\n",
       "      <td>100066</td>\n",
       "      <td>0.008184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307520</th>\n",
       "      <td>100067</td>\n",
       "      <td>0.079925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307521</th>\n",
       "      <td>100074</td>\n",
       "      <td>0.057574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307522</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.034120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307523</th>\n",
       "      <td>100091</td>\n",
       "      <td>0.197423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307524</th>\n",
       "      <td>100092</td>\n",
       "      <td>0.059264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307525</th>\n",
       "      <td>100106</td>\n",
       "      <td>0.064269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307526</th>\n",
       "      <td>100107</td>\n",
       "      <td>0.194147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307527</th>\n",
       "      <td>100109</td>\n",
       "      <td>0.043270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307528</th>\n",
       "      <td>100117</td>\n",
       "      <td>0.017642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307529</th>\n",
       "      <td>100128</td>\n",
       "      <td>0.099105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307530</th>\n",
       "      <td>100141</td>\n",
       "      <td>0.033428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307531</th>\n",
       "      <td>100150</td>\n",
       "      <td>0.038331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307532</th>\n",
       "      <td>100168</td>\n",
       "      <td>0.007844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307533</th>\n",
       "      <td>100169</td>\n",
       "      <td>0.053239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307534</th>\n",
       "      <td>100170</td>\n",
       "      <td>0.177454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307535</th>\n",
       "      <td>100171</td>\n",
       "      <td>0.056561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307536</th>\n",
       "      <td>100172</td>\n",
       "      <td>0.130192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307537</th>\n",
       "      <td>100184</td>\n",
       "      <td>0.089056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307538</th>\n",
       "      <td>100187</td>\n",
       "      <td>0.089740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307539</th>\n",
       "      <td>100212</td>\n",
       "      <td>0.020083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307540</th>\n",
       "      <td>100222</td>\n",
       "      <td>0.050660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356225</th>\n",
       "      <td>455963</td>\n",
       "      <td>0.032316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356226</th>\n",
       "      <td>455965</td>\n",
       "      <td>0.012499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356227</th>\n",
       "      <td>456007</td>\n",
       "      <td>0.276632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356228</th>\n",
       "      <td>456008</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356229</th>\n",
       "      <td>456009</td>\n",
       "      <td>0.027989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356230</th>\n",
       "      <td>456010</td>\n",
       "      <td>0.169321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356231</th>\n",
       "      <td>456011</td>\n",
       "      <td>0.026781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356232</th>\n",
       "      <td>456013</td>\n",
       "      <td>0.198025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356233</th>\n",
       "      <td>456028</td>\n",
       "      <td>0.079559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356234</th>\n",
       "      <td>456058</td>\n",
       "      <td>0.074840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356235</th>\n",
       "      <td>456111</td>\n",
       "      <td>0.079670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356236</th>\n",
       "      <td>456114</td>\n",
       "      <td>0.093726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356237</th>\n",
       "      <td>456115</td>\n",
       "      <td>0.022471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356238</th>\n",
       "      <td>456116</td>\n",
       "      <td>0.006498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356239</th>\n",
       "      <td>456119</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356240</th>\n",
       "      <td>456120</td>\n",
       "      <td>0.158790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356241</th>\n",
       "      <td>456122</td>\n",
       "      <td>0.050113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356242</th>\n",
       "      <td>456123</td>\n",
       "      <td>0.018473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356243</th>\n",
       "      <td>456166</td>\n",
       "      <td>0.069827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356244</th>\n",
       "      <td>456167</td>\n",
       "      <td>0.037918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356245</th>\n",
       "      <td>456168</td>\n",
       "      <td>0.026382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356246</th>\n",
       "      <td>456169</td>\n",
       "      <td>0.087625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356247</th>\n",
       "      <td>456170</td>\n",
       "      <td>0.012703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356248</th>\n",
       "      <td>456189</td>\n",
       "      <td>0.127826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356249</th>\n",
       "      <td>456202</td>\n",
       "      <td>0.086242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356250</th>\n",
       "      <td>456221</td>\n",
       "      <td>0.043408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356251</th>\n",
       "      <td>456222</td>\n",
       "      <td>0.044842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356252</th>\n",
       "      <td>456223</td>\n",
       "      <td>0.006335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356253</th>\n",
       "      <td>456224</td>\n",
       "      <td>0.035120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356254</th>\n",
       "      <td>456250</td>\n",
       "      <td>0.213722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR    TARGET\n",
       "307511      100001  0.027910\n",
       "307512      100005  0.123406\n",
       "307513      100013  0.034792\n",
       "307514      100028  0.047855\n",
       "307515      100038  0.136660\n",
       "307516      100042  0.035730\n",
       "307517      100057  0.006980\n",
       "307518      100065  0.022482\n",
       "307519      100066  0.008184\n",
       "307520      100067  0.079925\n",
       "307521      100074  0.057574\n",
       "307522      100090  0.034120\n",
       "307523      100091  0.197423\n",
       "307524      100092  0.059264\n",
       "307525      100106  0.064269\n",
       "307526      100107  0.194147\n",
       "307527      100109  0.043270\n",
       "307528      100117  0.017642\n",
       "307529      100128  0.099105\n",
       "307530      100141  0.033428\n",
       "307531      100150  0.038331\n",
       "307532      100168  0.007844\n",
       "307533      100169  0.053239\n",
       "307534      100170  0.177454\n",
       "307535      100171  0.056561\n",
       "307536      100172  0.130192\n",
       "307537      100184  0.089056\n",
       "307538      100187  0.089740\n",
       "307539      100212  0.020083\n",
       "307540      100222  0.050660\n",
       "...            ...       ...\n",
       "356225      455963  0.032316\n",
       "356226      455965  0.012499\n",
       "356227      456007  0.276632\n",
       "356228      456008  0.009560\n",
       "356229      456009  0.027989\n",
       "356230      456010  0.169321\n",
       "356231      456011  0.026781\n",
       "356232      456013  0.198025\n",
       "356233      456028  0.079559\n",
       "356234      456058  0.074840\n",
       "356235      456111  0.079670\n",
       "356236      456114  0.093726\n",
       "356237      456115  0.022471\n",
       "356238      456116  0.006498\n",
       "356239      456119  0.008417\n",
       "356240      456120  0.158790\n",
       "356241      456122  0.050113\n",
       "356242      456123  0.018473\n",
       "356243      456166  0.069827\n",
       "356244      456167  0.037918\n",
       "356245      456168  0.026382\n",
       "356246      456169  0.087625\n",
       "356247      456170  0.012703\n",
       "356248      456189  0.127826\n",
       "356249      456202  0.086242\n",
       "356250      456221  0.043408\n",
       "356251      456222  0.044842\n",
       "356252      456223  0.006335\n",
       "356253      456224  0.035120\n",
       "356254      456250  0.213722\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make submit file\n",
    "submit_file = pd.DataFrame({\"SK_ID_CURR\" : test_df[\"sk_id_curr\"].astype(\"int\"),\"TARGET\" : pred_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"light_gbm_test.csv\"\n",
    "submit_file.to_csv(\"../submit/\" + file_name, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Booster.dump_model of <lightgbm.basic.Booster object at 0x11b5cf320>>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.plot_importance(models_train, ax=ax, max_num_features=50, importance_type='split')\n",
    "lgb.plot_importance(models_train, ax=ax1, max_num_features=50, importance_type='gain')\n",
    "ax.set_title('Importance by splits')\n",
    "ax1.set_title('Importance by gain')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
